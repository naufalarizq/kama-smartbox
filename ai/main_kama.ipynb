{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cea7b761",
      "metadata": {
        "id": "cea7b761"
      },
      "source": [
        "# Classification Model eith Random Forest & XGBoost for Predicted Status_Spoiled\n",
        "### Train and compare RandomForest and XGBoost on dataset_kama.csv\n",
        "### Features: temperature, humidity, gas_level, jenis_makanan\n",
        "### Target: status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af285dc2",
      "metadata": {
        "id": "af285dc2"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05bdd04",
      "metadata": {
        "id": "b05bdd04",
        "outputId": "57d25b63-c36c-4619-c215-bb81c013160c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using dataset: D:\\naufalarizq\\project\\kama-smartbox\\ai\\dataset\\dataset_kama.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Try import XGBoost\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    has_xgb = True\n",
        "except Exception:\n",
        "    has_xgb = False\n",
        "\n",
        "# locate dataset (robust search)\n",
        "def find_dataset(name='dataset_kama.csv', max_up=6):\n",
        "    p = Path.cwd().resolve()\n",
        "    # check cwd/ai/dataset\n",
        "    candidate = p / 'ai' / 'dataset' / name\n",
        "    if candidate.exists():\n",
        "        return candidate\n",
        "    # walk up\n",
        "    for _ in range(max_up):\n",
        "        p = p.parent\n",
        "        candidate = p / 'ai' / 'dataset' / name\n",
        "        if candidate.exists():\n",
        "            return candidate\n",
        "    # try repository relative path\n",
        "    candidate = Path(__file__).resolve().parents[1] / 'ai' / 'dataset' / name if '__file__' in globals() else Path('ai') / 'dataset' / name\n",
        "    if candidate.exists():\n",
        "        return candidate\n",
        "    raise FileNotFoundError(f\"Could not find {name}\")\n",
        "\n",
        "try:\n",
        "    data_path = find_dataset()\n",
        "except Exception:\n",
        "    # fallback: try relative path from repo root\n",
        "    data_path = Path('ai') / 'dataset' / 'dataset_kama.csv'\n",
        "\n",
        "print('Using dataset:', data_path)\n",
        "df = pd.read_csv(data_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ccd3d8",
      "metadata": {
        "id": "89ccd3d8",
        "outputId": "4f2c150c-d533-433e-a02f-107b6704f37f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target classes: ['bad' 'good' 'warning']\n",
            "Train/Test shapes: (2626, 4) (657, 4)\n"
          ]
        }
      ],
      "source": [
        "# normalize column names map\n",
        "cols_map = {c.lower().strip(): c for c in df.columns}\n",
        "get_col = lambda name: cols_map.get(name.lower())\n",
        "\n",
        "feat_names = [get_col('temperature'), get_col('humidity'), get_col('gas_level'), get_col('jenis_makanan')]\n",
        "feat_names = [f for f in feat_names if f is not None]\n",
        "if not feat_names:\n",
        "    raise RuntimeError('No feature columns found in dataset (temperature, humidity, gas_level, jenis_makanan)')\n",
        "\n",
        "target_col = get_col('status')\n",
        "if target_col is None:\n",
        "    raise RuntimeError('Target column \"status\" not found in dataset')\n",
        "\n",
        "# Drop rows missing target\n",
        "df = df.dropna(subset=[target_col])\n",
        "\n",
        "# Prepare X and y\n",
        "X = df[feat_names].copy()\n",
        "y = df[target_col].astype(str).str.strip()\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "print('Target classes:', le.classes_)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)\n",
        "print('Train/Test shapes:', X_train.shape, X_test.shape)\n",
        "\n",
        "# Build preprocessing\n",
        "numeric_features = [c for c in feat_names if c.lower() in ('temperature','humidity','gas_level')]\n",
        "cat_features = [c for c in feat_names if c not in numeric_features]\n",
        "\n",
        "numeric_transform = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "])\n",
        "cat_transform = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transform, numeric_features),\n",
        "    ('cat', cat_transform, cat_features),\n",
        "], remainder='drop')\n",
        "\n",
        "models_dir = Path('ai') / 'models'\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "results = {}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6044a34",
      "metadata": {
        "id": "f6044a34",
        "outputId": "4367a811-1d64-4ea6-889a-cee9cac7fe91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training RandomForest...\n",
            "RandomForest accuracy: 0.9939117199391172\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       1.00      1.00      1.00       500\n",
            "        good       0.96      0.98      0.97        56\n",
            "     warning       0.99      0.97      0.98       101\n",
            "\n",
            "    accuracy                           0.99       657\n",
            "   macro avg       0.98      0.98      0.98       657\n",
            "weighted avg       0.99      0.99      0.99       657\n",
            "\n",
            "Saved RandomForest to ai\\models\\rf_status_model.pkl\n",
            "RandomForest accuracy: 0.9939117199391172\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       1.00      1.00      1.00       500\n",
            "        good       0.96      0.98      0.97        56\n",
            "     warning       0.99      0.97      0.98       101\n",
            "\n",
            "    accuracy                           0.99       657\n",
            "   macro avg       0.98      0.98      0.98       657\n",
            "weighted avg       0.99      0.99      0.99       657\n",
            "\n",
            "Saved RandomForest to ai\\models\\rf_status_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# Random Forest\n",
        "rf_pipeline = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('clf', RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1, class_weight='balanced')),\n",
        "])\n",
        "print('\\nTraining RandomForest...')\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "y_pred_rf = rf_pipeline.predict(X_test)\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print('RandomForest accuracy:', acc_rf)\n",
        "print(classification_report(y_test, y_pred_rf, target_names=le.classes_))\n",
        "results['random_forest'] = {'accuracy': acc_rf}\n",
        "joblib.dump({'model': rf_pipeline, 'label_encoder': le}, models_dir / 'rf_status_model.pkl')\n",
        "print('Saved RandomForest to', models_dir / 'rf_status_model.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69c907fa",
      "metadata": {
        "id": "69c907fa",
        "outputId": "cb1ce450-bc26-4f6b-fa94-a2debb92d8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training XGBoost...\n",
            "XGBoost accuracy: 0.9939117199391172\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       1.00      1.00      1.00       500\n",
            "        good       1.00      0.96      0.98        56\n",
            "     warning       0.97      0.99      0.98       101\n",
            "\n",
            "    accuracy                           0.99       657\n",
            "   macro avg       0.99      0.98      0.99       657\n",
            "weighted avg       0.99      0.99      0.99       657\n",
            "\n",
            "Saved XGBoost to ai\\models\\xgb_status_model.pkl\n",
            "XGBoost accuracy: 0.9939117199391172\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       1.00      1.00      1.00       500\n",
            "        good       1.00      0.96      0.98        56\n",
            "     warning       0.97      0.99      0.98       101\n",
            "\n",
            "    accuracy                           0.99       657\n",
            "   macro avg       0.99      0.98      0.99       657\n",
            "weighted avg       0.99      0.99      0.99       657\n",
            "\n",
            "Saved XGBoost to ai\\models\\xgb_status_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# XGBoost (if available)\n",
        "if has_xgb:\n",
        "    print('\\nTraining XGBoost...')\n",
        "    xgb_pipeline = Pipeline([\n",
        "        ('pre', preprocessor),\n",
        "        ('clf', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', verbosity=0, random_state=42))\n",
        "    ])\n",
        "    xgb_pipeline.fit(X_train, y_train)\n",
        "    y_pred_xgb = xgb_pipeline.predict(X_test)\n",
        "    acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "    print('XGBoost accuracy:', acc_xgb)\n",
        "    print(classification_report(y_test, y_pred_xgb, target_names=le.classes_))\n",
        "    results['xgboost'] = {'accuracy': acc_xgb}\n",
        "    joblib.dump({'model': xgb_pipeline, 'label_encoder': le}, models_dir / 'xgb_status_model.pkl')\n",
        "    print('Saved XGBoost to', models_dir / 'xgb_status_model.pkl')\n",
        "else:\n",
        "    print('\\nXGBoost not available in the environment. Install xgboost to run it: pip install xgboost')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9d9e88",
      "metadata": {
        "id": "cc9d9e88",
        "outputId": "edd0b8da-b359-4d19-a708-026d171591e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary:\n",
            "random_forest {'accuracy': 0.9939117199391172}\n",
            "xgboost {'accuracy': 0.9939117199391172}\n"
          ]
        }
      ],
      "source": [
        "print('\\nSummary:')\n",
        "for k,v in results.items():\n",
        "    print(k, v)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bde319b",
      "metadata": {
        "id": "7bde319b"
      },
      "source": [
        "# Predicted Model with Gradient Boosting Regressor / XGBoost Regressor for Predicted Spoiled Date\n",
        "### Predicted Model with Gradient Boosting Regressor / XGBoost Regressor for Predicted Spoiled Date\n",
        "### Features: temperature, humidity, gas_level, jenis_makanan\n",
        "### Target: predicted_spoiled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f316253",
      "metadata": {
        "id": "1f316253"
      },
      "outputs": [],
      "source": [
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cff77609",
      "metadata": {
        "id": "cff77609",
        "outputId": "9379e69b-a4d4-425a-daf9-4167ee5725a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using dataset: D:\\naufalarizq\\project\\kama-smartbox\\ai\\dataset\\dataset_kama.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Try to import XGBoost regressor\n",
        "try:\n",
        "    from xgboost import XGBRegressor\n",
        "    has_xgb = True\n",
        "except Exception:\n",
        "    has_xgb = False\n",
        "\n",
        "# locate dataset\n",
        "data_path = Path('ai') / 'dataset' / 'dataset_kama.csv'\n",
        "if not data_path.exists():\n",
        "    # try a bit more robust search\n",
        "    p = Path.cwd().resolve()\n",
        "    for _ in range(6):\n",
        "        cand = p / 'ai' / 'dataset' / 'dataset_kama.csv'\n",
        "        if cand.exists():\n",
        "            data_path = cand\n",
        "            break\n",
        "        if p.parent == p:\n",
        "            break\n",
        "        p = p.parent\n",
        "\n",
        "print('Using dataset:', data_path)\n",
        "df = pd.read_csv(data_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41ae2178",
      "metadata": {
        "id": "41ae2178"
      },
      "outputs": [],
      "source": [
        "# normalize column mapping\n",
        "cols_map = {c.lower().strip(): c for c in df.columns}\n",
        "get_col = lambda name: cols_map.get(name.lower())\n",
        "\n",
        "features = [get_col('temperature'), get_col('humidity'), get_col('gas_level'), get_col('jenis_makanan')]\n",
        "features = [f for f in features if f is not None]\n",
        "if not features:\n",
        "    raise RuntimeError('Required feature columns not found')\n",
        "\n",
        "target = get_col('predicted_spoiled') or get_col('predicted_spoil') or get_col('predicted_spoiled')\n",
        "if target is None:\n",
        "    raise RuntimeError('Target column \"predicted_spoiled\" not found in dataset')\n",
        "\n",
        "# Drop rows missing target\n",
        "df = df.dropna(subset=[target])\n",
        "\n",
        "X = df[features].copy()\n",
        "y = pd.to_numeric(df[target], errors='coerce')\n",
        "\n",
        "# Drop rows where target is NaN after conversion\n",
        "mask_valid = y.notna()\n",
        "X = X.loc[mask_valid]\n",
        "y = y.loc[mask_valid]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3c83d91",
      "metadata": {
        "id": "a3c83d91",
        "outputId": "a0ab79ca-8d51-4cd7-d24c-39a462f2561d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train/Test shapes: (2626, 4) (657, 4)\n"
          ]
        }
      ],
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print('Train/Test shapes:', X_train.shape, X_test.shape)\n",
        "\n",
        "# Separate numeric and categorical features\n",
        "numeric_features = [c for c in features if c.lower() in ('temperature','humidity','gas_level')]\n",
        "categorical_features = [c for c in features if c not in numeric_features]\n",
        "\n",
        "numeric_transform = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "])\n",
        "cat_transform = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transform, numeric_features),\n",
        "    ('cat', cat_transform, categorical_features),\n",
        "], remainder='drop')\n",
        "\n",
        "models_dir = Path('ai') / 'models'\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d30df17",
      "metadata": {
        "id": "3d30df17",
        "outputId": "e5f225be-7f56-4391-af7b-64e35692e0ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training GradientBoostingRegressor...\n",
            "GBR RMSE: 0.0311 MAE: 0.0246 R2: 0.9986\n",
            "Saved GBR to ai\\models\\gbr_predicted_spoiled.pkl\n",
            "GBR RMSE: 0.0311 MAE: 0.0246 R2: 0.9986\n",
            "Saved GBR to ai\\models\\gbr_predicted_spoiled.pkl\n"
          ]
        }
      ],
      "source": [
        "# Gradient Boosting Regressor\n",
        "gbr_pipeline = Pipeline([\n",
        "    ('pre', preprocessor),\n",
        "    ('reg', GradientBoostingRegressor(random_state=42))\n",
        "])\n",
        "print('\\nTraining GradientBoostingRegressor...')\n",
        "gbr_pipeline.fit(X_train, y_train)\n",
        "y_pred_gbr = gbr_pipeline.predict(X_test)\n",
        "# compute RMSE in a way compatible with older sklearn versions\n",
        "rmse_gbr = np.sqrt(mean_squared_error(y_test, y_pred_gbr))\n",
        "mae_gbr = mean_absolute_error(y_test, y_pred_gbr)\n",
        "r2_gbr = r2_score(y_test, y_pred_gbr)\n",
        "print('GBR RMSE:', f\"{rmse_gbr:.4f}\", 'MAE:', f\"{mae_gbr:.4f}\", 'R2:', f\"{r2_gbr:.4f}\")\n",
        "results['gbr'] = {'rmse': rmse_gbr, 'mae': mae_gbr, 'r2': r2_gbr}\n",
        "joblib.dump({'model': gbr_pipeline}, models_dir / 'gbr_predicted_spoiled.pkl')\n",
        "print('Saved GBR to', models_dir / 'gbr_predicted_spoiled.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b33c2522",
      "metadata": {
        "id": "b33c2522",
        "outputId": "b2c43732-3589-4e1b-edd0-ba5df8ea5b83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training XGBRegressor...\n",
            "XGB RMSE: 0.0302 MAE: 0.0238 R2: 0.9986\n",
            "Saved XGB to ai\\models\\xgb_predicted_spoiled.pkl\n",
            "XGB RMSE: 0.0302 MAE: 0.0238 R2: 0.9986\n",
            "Saved XGB to ai\\models\\xgb_predicted_spoiled.pkl\n"
          ]
        }
      ],
      "source": [
        "# XGBoost Regressor\n",
        "if has_xgb:\n",
        "    print('\\nTraining XGBRegressor...')\n",
        "    xgb_pipeline = Pipeline([\n",
        "        ('pre', preprocessor),\n",
        "        ('reg', XGBRegressor(random_state=42, verbosity=0))\n",
        "    ])\n",
        "    xgb_pipeline.fit(X_train, y_train)\n",
        "    y_pred_xgb = xgb_pipeline.predict(X_test)\n",
        "    rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
        "    mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "    r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "    print('XGB RMSE:', f\"{rmse_xgb:.4f}\", 'MAE:', f\"{mae_xgb:.4f}\", 'R2:', f\"{r2_xgb:.4f}\")\n",
        "    results['xgb'] = {'rmse': rmse_xgb, 'mae': mae_xgb, 'r2': r2_xgb}\n",
        "    joblib.dump({'model': xgb_pipeline}, models_dir / 'xgb_predicted_spoiled.pkl')\n",
        "    print('Saved XGB to', models_dir / 'xgb_predicted_spoiled.pkl')\n",
        "else:\n",
        "    print('\\nXGBoost not installed; to run XGBRegressor install xgboost (pip install xgboost)')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "348140f9",
      "metadata": {
        "id": "348140f9",
        "outputId": "76f7ec5b-998f-4090-84d2-34a3bf7c988c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample predictions:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>gas_level</th>\n",
              "      <th>jenis_makanan</th>\n",
              "      <th>actual</th>\n",
              "      <th>pred_gbr</th>\n",
              "      <th>pred_xgb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>23.12</td>\n",
              "      <td>72.72</td>\n",
              "      <td>402.42</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-0.31</td>\n",
              "      <td>-0.283222</td>\n",
              "      <td>-0.319031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>19.52</td>\n",
              "      <td>79.55</td>\n",
              "      <td>414.84</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-1.098060</td>\n",
              "      <td>-1.062061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2416</th>\n",
              "      <td>22.12</td>\n",
              "      <td>68.58</td>\n",
              "      <td>405.28</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-0.24</td>\n",
              "      <td>-0.284994</td>\n",
              "      <td>-0.289740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1650</th>\n",
              "      <td>23.43</td>\n",
              "      <td>51.53</td>\n",
              "      <td>416.55</td>\n",
              "      <td>fruits</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.602498</td>\n",
              "      <td>0.617029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2552</th>\n",
              "      <td>28.89</td>\n",
              "      <td>86.32</td>\n",
              "      <td>417.74</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-0.36</td>\n",
              "      <td>-0.365749</td>\n",
              "      <td>-0.405895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2913</th>\n",
              "      <td>28.65</td>\n",
              "      <td>92.79</td>\n",
              "      <td>418.06</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-0.68</td>\n",
              "      <td>-0.663274</td>\n",
              "      <td>-0.703079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2664</th>\n",
              "      <td>26.29</td>\n",
              "      <td>88.11</td>\n",
              "      <td>406.98</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-0.67</td>\n",
              "      <td>-0.682336</td>\n",
              "      <td>-0.724387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>18.56</td>\n",
              "      <td>72.64</td>\n",
              "      <td>409.11</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-0.83</td>\n",
              "      <td>-0.831124</td>\n",
              "      <td>-0.805767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1242</th>\n",
              "      <td>24.25</td>\n",
              "      <td>54.04</td>\n",
              "      <td>417.13</td>\n",
              "      <td>fruits</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.640874</td>\n",
              "      <td>0.629211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1641</th>\n",
              "      <td>20.98</td>\n",
              "      <td>91.62</td>\n",
              "      <td>409.77</td>\n",
              "      <td>fruits</td>\n",
              "      <td>-1.42</td>\n",
              "      <td>-1.401223</td>\n",
              "      <td>-1.373072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      temperature  humidity  gas_level jenis_makanan  actual  pred_gbr  \\\n",
              "1657        23.12     72.72     402.42        fruits   -0.31 -0.283222   \n",
              "1298        19.52     79.55     414.84        fruits   -1.06 -1.098060   \n",
              "2416        22.12     68.58     405.28        fruits   -0.24 -0.284994   \n",
              "1650        23.43     51.53     416.55        fruits    0.61  0.602498   \n",
              "2552        28.89     86.32     417.74        fruits   -0.36 -0.365749   \n",
              "2913        28.65     92.79     418.06        fruits   -0.68 -0.663274   \n",
              "2664        26.29     88.11     406.98        fruits   -0.67 -0.682336   \n",
              "238         18.56     72.64     409.11        fruits   -0.83 -0.831124   \n",
              "1242        24.25     54.04     417.13        fruits    0.58  0.640874   \n",
              "1641        20.98     91.62     409.77        fruits   -1.42 -1.401223   \n",
              "\n",
              "      pred_xgb  \n",
              "1657 -0.319031  \n",
              "1298 -1.062061  \n",
              "2416 -0.289740  \n",
              "1650  0.617029  \n",
              "2552 -0.405895  \n",
              "2913 -0.703079  \n",
              "2664 -0.724387  \n",
              "238  -0.805767  \n",
              "1242  0.629211  \n",
              "1641 -1.373072  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary metrics:\n",
            "gbr {'rmse': np.float64(0.031070900581085727), 'mae': 0.02461581919976353, 'r2': 0.9985618239683981}\n",
            "xgb {'rmse': np.float64(0.030218331775201328), 'mae': 0.0238092555284863, 'r2': 0.9986396666850849}\n",
            "Could not save full predictions: Cannot save file into a non-existent directory: 'ai\\dataset'\n"
          ]
        }
      ],
      "source": [
        "# Attach predictions to a sample and display\n",
        "sample = X_test.copy()\n",
        "sample['actual'] = y_test\n",
        "sample['pred_gbr'] = gbr_pipeline.predict(X_test)\n",
        "if has_xgb:\n",
        "    sample['pred_xgb'] = xgb_pipeline.predict(X_test)\n",
        "\n",
        "from IPython.display import display\n",
        "print('\\nSample predictions:')\n",
        "display(sample.head(10))\n",
        "\n",
        "print('\\nSummary metrics:')\n",
        "for k,v in results.items():\n",
        "    print(k, v)\n",
        "\n",
        "# Optionally, add predictions back to original dataframe and save augmented file\n",
        "try:\n",
        "    df_out = df.copy()\n",
        "    # compute full-dataset predictions where possible\n",
        "    X_full = df_out[features].copy()\n",
        "    df_out['pred_gbr'] = gbr_pipeline.predict(X_full)\n",
        "    if has_xgb:\n",
        "        df_out['pred_xgb'] = xgb_pipeline.predict(X_full)\n",
        "    out_path = Path('ai') / 'dataset' / 'dataset_kama_with_reg_preds.csv'\n",
        "    df_out.to_csv(out_path, index=False)\n",
        "    print('Saved augmented dataset with regressor predictions to', out_path)\n",
        "except Exception as e:\n",
        "    print('Could not save full predictions:', e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab782b9d",
      "metadata": {
        "id": "ab782b9d"
      },
      "source": [
        "# Classification Models with MLP kecil (1–2 hidden layer, 8–16 neuron) then Convert to .tflite (later xx.c) for Device ESP32\n",
        "### Classification Models with small MLP (1-2 hidden layers, 8-16 neurons) then Convert to .tflite (for ESP32)\n",
        "### Features: temperature, humidity, gas_level, jenis_makanan\n",
        "### Target: status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99a6fe6e",
      "metadata": {
        "id": "99a6fe6e"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb4385fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb4385fe",
        "outputId": "e2d3745b-8b17-461b-dea1-a09538012692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using dataset: /content/dataset_kama.csv\n"
          ]
        }
      ],
      "source": [
        "# robust dataset lookup\n",
        "data_path = Path('/content/dataset_kama.csv')\n",
        "if not data_path.exists():\n",
        "    p = Path.cwd().resolve()\n",
        "    for _ in range(6):\n",
        "        cand = p / 'ai' / 'dataset' / 'dataset_kama.csv'\n",
        "        if cand.exists():\n",
        "            data_path = cand\n",
        "            break\n",
        "        if p.parent == p:\n",
        "            break\n",
        "        p = p.parent\n",
        "\n",
        "print('Using dataset:', data_path)\n",
        "df = pd.read_csv(data_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "84lPBw54t9Ki"
      },
      "id": "84lPBw54t9Ki",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4085d65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4085d65",
        "outputId": "2a9b5ab3-fc7e-44dc-9739-52f94e778fc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target classes: ['bad' 'good' 'warning']\n"
          ]
        }
      ],
      "source": [
        "# normalize column names map\n",
        "cols_map = {c.lower().strip(): c for c in df.columns}\n",
        "get_col = lambda name: cols_map.get(name.lower())\n",
        "\n",
        "features = [get_col('temperature'), get_col('humidity'), get_col('gas_level'), get_col('jenis_makanan')]\n",
        "features = [f for f in features if f is not None]\n",
        "if not features:\n",
        "    raise RuntimeError('Required feature columns not found')\n",
        "\n",
        "target_col = get_col('status')\n",
        "if target_col is None:\n",
        "    raise RuntimeError('Target column \"status\" not found')\n",
        "\n",
        "# Prepare dataset\n",
        "df = df.dropna(subset=[target_col])\n",
        "X = df[features].copy()\n",
        "y = df[target_col].astype(str).str.strip()\n",
        "\n",
        "# Encode target\n",
        "le = LabelEncoder()\n",
        "y_enc = le.fit_transform(y)\n",
        "print('Target classes:', le.classes_)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11ec4c6e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11ec4c6e",
        "outputId": "6913e100-d948-4b3e-e49a-8177967ab964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Test shapes: (2626, 4) (657, 4)\n",
            "Saved preprocessor and label encoder to ai/models/mlp_preproc_label.pkl\n"
          ]
        }
      ],
      "source": [
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_enc, test_size=0.2, random_state=42, stratify=y_enc)\n",
        "print('Train/Test shapes:', X_train.shape, X_test.shape)\n",
        "\n",
        "# Preprocessing pipelines\n",
        "numeric_features = [c for c in features if c.lower() in ('temperature','humidity','gas_level')]\n",
        "cat_features = [c for c in features if c not in numeric_features]\n",
        "\n",
        "numeric_transform = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler()),\n",
        "])\n",
        "cat_transform = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
        "])\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', numeric_transform, numeric_features),\n",
        "    ('cat', cat_transform, cat_features),\n",
        "], remainder='drop')\n",
        "\n",
        "# Fit preprocessor and transform\n",
        "X_train_p = preprocessor.fit_transform(X_train)\n",
        "X_test_p = preprocessor.transform(X_test)\n",
        "\n",
        "models_dir = Path('ai') / 'models'\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save preprocessor + label encoder for deployment pipeline\n",
        "joblib.dump({'preprocessor': preprocessor, 'label_encoder': le}, models_dir / 'mlp_preproc_label.pkl')\n",
        "print('Saved preprocessor and label encoder to', models_dir / 'mlp_preproc_label.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b203f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2b203f0",
        "outputId": "bf1c98f6-ca15-485b-d3e6-50c9bd0300bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow detected. Will train Keras MLP and attempt TFLite conversion.\n"
          ]
        }
      ],
      "source": [
        "# Try to use TensorFlow (Keras). If not available, fallback to sklearn MLPClassifier\n",
        "use_keras = False\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    use_keras = True\n",
        "    print('TensorFlow detected. Will train Keras MLP and attempt TFLite conversion.')\n",
        "except Exception as e:\n",
        "    print('TensorFlow not available, falling back to sklearn MLPClassifier. Error:', e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43be62e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43be62e0",
        "outputId": "4bb6e282-4558-4d03-cab4-0005d3e78596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training mlp_16\n",
            "mlp_16 test accuracy: 0.9452\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.97      0.99      0.98       500\n",
            "        good       0.91      0.77      0.83        56\n",
            "     warning       0.83      0.81      0.82       101\n",
            "\n",
            "    accuracy                           0.95       657\n",
            "   macro avg       0.90      0.86      0.88       657\n",
            "weighted avg       0.94      0.95      0.94       657\n",
            "\n",
            "Saved Keras model to ai/models/mlp_16_status_model.h5\n",
            "\n",
            "Training mlp_16_8\n",
            "mlp_16_8 test accuracy: 0.9802\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.99      0.99      0.99       500\n",
            "        good       1.00      0.95      0.97        56\n",
            "     warning       0.93      0.94      0.94       101\n",
            "\n",
            "    accuracy                           0.98       657\n",
            "   macro avg       0.97      0.96      0.97       657\n",
            "weighted avg       0.98      0.98      0.98       657\n",
            "\n",
            "Saved Keras model to ai/models/mlp_16_8_status_model.h5\n",
            "Saved wrapper to ai/models/mlp_models_wrapper.pkl\n",
            "Saved artifact at '/tmp/tmpjcmjm04k'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='keras_tensor_4')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139582057859984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582057863440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582057857872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582057863824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582057859216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582057863248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved TFLite model to ai/models/mlp_status_model.tflite size (bytes): 3076\n",
            "\n",
            "Done. Models and artifacts are under ai/models/.\n"
          ]
        }
      ],
      "source": [
        "if use_keras:\n",
        "    # Build small MLP: allow 1-2 hidden layers with 8-16 neurons\n",
        "    input_dim = X_train_p.shape[1]\n",
        "    num_classes = len(le.classes_)\n",
        "\n",
        "    def build_mlp(hidden_layers=(16,)):\n",
        "        model = keras.Sequential()\n",
        "        model.add(keras.layers.Input(shape=(input_dim,)))\n",
        "        for units in hidden_layers:\n",
        "            model.add(keras.layers.Dense(units, activation='relu'))\n",
        "        model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
        "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    # two architectures to compare\n",
        "    archs = {'mlp_16': (16,), 'mlp_16_8': (16,8)}\n",
        "    trained_models = {}\n",
        "    for name, arch in archs.items():\n",
        "        print('\\nTraining', name)\n",
        "        model = build_mlp(arch)\n",
        "        # small training epochs because dataset may be small\n",
        "        history = model.fit(X_train_p, y_train, epochs=30, batch_size=32, validation_split=0.1, verbose=0)\n",
        "        loss, acc = model.evaluate(X_test_p, y_test, verbose=0)\n",
        "        print(f'{name} test accuracy: {acc:.4f}')\n",
        "        y_pred = np.argmax(model.predict(X_test_p), axis=1)\n",
        "        from sklearn.metrics import classification_report\n",
        "        print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "        trained_models[name] = model\n",
        "        # save keras model\n",
        "        model_path = models_dir / f'{name}_status_model.h5'\n",
        "        model.save(model_path)\n",
        "        print('Saved Keras model to', model_path)\n",
        "\n",
        "    # Save best or last model to pkl wrapper: store model path + preprocessor + label encoder\n",
        "    wrapper = {'models': {n: str(models_dir / f\"{n}_status_model.h5\") for n in trained_models.keys()}, 'label_encoder': le}\n",
        "    joblib.dump(wrapper, models_dir / 'mlp_models_wrapper.pkl')\n",
        "    print('Saved wrapper to', models_dir / 'mlp_models_wrapper.pkl')\n",
        "\n",
        "    # Convert the last trained model to TFLite with default optimizations (dynamic range)\n",
        "    try:\n",
        "        last_model = list(trained_models.values())[-1]\n",
        "        converter = tf.lite.TFLiteConverter.from_keras_model(last_model)\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        tflite_model = converter.convert()\n",
        "        tflite_path = models_dir / 'mlp_status_model.tflite'\n",
        "        tflite_path.write_bytes(tflite_model)\n",
        "        print('Saved TFLite model to', tflite_path, 'size (bytes):', tflite_path.stat().st_size)\n",
        "    except Exception as e:\n",
        "        print('TFLite conversion failed:', e)\n",
        "\n",
        "else:\n",
        "    # Fallback: sklearn MLPClassifier\n",
        "    from sklearn.neural_network import MLPClassifier\n",
        "    print('\\nTraining sklearn MLPClassifier (fallback)...')\n",
        "    mlp = MLPClassifier(hidden_layer_sizes=(16,8), max_iter=500, random_state=42)\n",
        "    mlp.fit(X_train_p, y_train)\n",
        "    y_pred = mlp.predict(X_test_p)\n",
        "    from sklearn.metrics import classification_report\n",
        "    acc = (y_pred == y_test).mean()\n",
        "    print('sklearn MLP accuracy:', acc)\n",
        "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "    # Save sklearn model and preprocessor+label encoder already saved\n",
        "    joblib.dump({'model': mlp}, models_dir / 'mlp_sklearn_status_model.pkl')\n",
        "    print('Saved sklearn MLP to', models_dir / 'mlp_sklearn_status_model.pkl')\n",
        "\n",
        "print('\\nDone. Models and artifacts are under ai/models/.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantize Keras MLP to INT8 TFLite and generate C array (.cc/.h) for TFLite Micro (ESP32)\n",
        "# Requires TensorFlow installed. Uses representative dataset from preprocessor + dataset.\n",
        "\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "models_dir = Path('ai') / 'models'\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Locate keras model path from wrapper if available\n",
        "wrapper_path = models_dir / 'mlp_models_wrapper.pkl'\n",
        "model_h5_path = None\n",
        "if wrapper_path.exists():\n",
        "    try:\n",
        "        wrapper = joblib.load(wrapper_path)\n",
        "        # wrapper may contain mapping to model filenames\n",
        "        if isinstance(wrapper, dict) and 'models' in wrapper:\n",
        "            # pick the first model\n",
        "            first = next(iter(wrapper['models'].values()))\n",
        "            model_h5_path = Path(first)\n",
        "    except Exception as e:\n",
        "        print('Could not read wrapper:', e)\n",
        "\n",
        "# fallback to common filenames\n",
        "if model_h5_path is None or not model_h5_path.exists():\n",
        "    candidates = list(models_dir.glob('*mlp*_status_model.h5')) + list(models_dir.glob('*status_model.h5'))\n",
        "    if candidates:\n",
        "        model_h5_path = candidates[-1]\n",
        "\n",
        "if model_h5_path is None or not model_h5_path.exists():\n",
        "    print('No Keras .h5 model found in', models_dir, '— quantization skipped. Ensure you trained a Keras MLP and saved .h5')\n",
        "else:\n",
        "    print('Found Keras model:', model_h5_path)\n",
        "\n",
        "    # Load preprocessor to prepare representative dataset\n",
        "    preproc_path = models_dir / 'mlp_preproc_label.pkl'\n",
        "    if not preproc_path.exists():\n",
        "        print('Preprocessor file not found at', preproc_path, '— cannot create representative dataset; quantization may still work but calibration will be limited')\n",
        "        preprocessor = None\n",
        "    else:\n",
        "        preproc = joblib.load(preproc_path)\n",
        "        preprocessor = preproc.get('preprocessor') if isinstance(preproc, dict) and 'preprocessor' in preproc else preproc.get('preprocessor') if hasattr(preproc,'get') else preproc\n",
        "\n",
        "    # Load dataset for representative samples\n",
        "    data_path = Path('/content/dataset_kama.csv')\n",
        "    if not data_path.exists():\n",
        "        # try a bit more robust search\n",
        "        p = Path.cwd().resolve()\n",
        "        for _ in range(6):\n",
        "            cand = p / 'content' / 'dataset_kama.csv'\n",
        "            if cand.exists():\n",
        "                data_path = cand\n",
        "                break\n",
        "            if p.parent == p:\n",
        "                break\n",
        "            p = p.parent\n",
        "\n",
        "    df = pd.read_csv(data_path)\n",
        "    # normalize columns\n",
        "    cols_map = {c.lower().strip(): c for c in df.columns}\n",
        "    get_col = lambda name: cols_map.get(name.lower())\n",
        "    features = [get_col('temperature'), get_col('humidity'), get_col('gas_level'), get_col('jenis_makanan')]\n",
        "    features = [f for f in features if f is not None]\n",
        "\n",
        "    # prepare representative dataset generator\n",
        "    rep_samples = None\n",
        "    if preprocessor is not None:\n",
        "        # take up to 100 rows of features without NaN\n",
        "        Xrep = df[features].dropna().head(200)\n",
        "        if not Xrep.empty:\n",
        "            Xrep_p = preprocessor.transform(Xrep)\n",
        "            # ensure float32\n",
        "            Xrep_p = Xrep_p.astype(np.float32)\n",
        "            rep_samples = Xrep_p\n",
        "\n",
        "    # proceed with TensorFlow conversion\n",
        "    try:\n",
        "        import tensorflow as tf\n",
        "        from tensorflow import keras\n",
        "    except Exception as e:\n",
        "        print('TensorFlow not available — cannot convert to TFLite here:', e)\n",
        "        rep_samples = None\n",
        "\n",
        "    if 'tf' in globals() and model_h5_path is not None and model_h5_path.exists():\n",
        "        # load Keras model\n",
        "        try:\n",
        "            model = keras.models.load_model(str(model_h5_path))\n",
        "        except Exception as e:\n",
        "            print('Failed to load Keras model:', e)\n",
        "            model = None\n",
        "\n",
        "        if model is not None:\n",
        "            converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "            if rep_samples is not None:\n",
        "                def representative_dataset_gen():\n",
        "                    for i in range(min(len(rep_samples), 100)):\n",
        "                        # converter expects a list of input arrays\n",
        "                        yield [rep_samples[i:i+1]]\n",
        "                converter.representative_dataset = representative_dataset_gen\n",
        "                # request int8 ops\n",
        "                converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "                converter.inference_input_type = tf.int8\n",
        "                converter.inference_output_type = tf.int8\n",
        "            else:\n",
        "                print('No representative samples available — converter will use default quantization (may be float or dynamic range).')\n",
        "\n",
        "            try:\n",
        "                tflite_model = converter.convert()\n",
        "                tflite_path = models_dir / 'mlp_status_model_quant.tflite'\n",
        "                tflite_path.write_bytes(tflite_model)\n",
        "                print('Saved quantized TFLite model to', tflite_path, 'size:', tflite_path.stat().st_size)\n",
        "\n",
        "                # Generate C array (.h/.cc) for TFLite Micro\n",
        "                name = 'mlp_status_model_quant'\n",
        "                array_name = name + '_tflite'\n",
        "                header_path = models_dir / f'{name}.h'\n",
        "                cc_path = models_dir / f'{name}.cc'\n",
        "\n",
        "                b = tflite_model\n",
        "                # write header\n",
        "                with open(header_path, 'w', encoding='utf-8') as hf:\n",
        "                    hf.write('#ifndef MODEL_DATA_H\\n')\n",
        "                    hf.write('#define MODEL_DATA_H\\n\\n')\n",
        "                    hf.write(f'#include <cstdint>\\n\\n')\n",
        "                    hf.write(f'extern const unsigned char {array_name}[];\\n')\n",
        "                    hf.write(f'extern const unsigned int {array_name}_len;\\n\\n')\n",
        "                    hf.write('#endif // MODEL_DATA_H\\n')\n",
        "\n",
        "                # write cc with array bytes\n",
        "                with open(cc_path, 'w', encoding='utf-8') as cf:\n",
        "                    cf.write('#include \"'+header_path.name+'\"\\n\\n')\n",
        "                    cf.write(f'const unsigned char {array_name}[] = {{\\n')\n",
        "                    # write as hex, 12 bytes per line\n",
        "                    for i in range(0, len(b), 12):\n",
        "                        chunk = b[i:i+12]\n",
        "                        line = ', '.join('0x{:02x}'.format(x) for x in chunk)\n",
        "                        cf.write('  ' + line + ',\\n')\n",
        "                    cf.write('};\\n\\n')\n",
        "                    cf.write(f'const unsigned int {array_name}_len = {len(b)};\\n')\n",
        "\n",
        "                print('Generated C files:', header_path, cc_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print('TFLite conversion failed:', e)\n",
        "        else:\n",
        "            print('Model could not be loaded; conversion skipped')\n",
        "    else:\n",
        "        print('Skipping TFLite conversion: TensorFlow or model not available.')\n",
        "\n",
        "print('Quantization cell finished.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v29qy9PSxKOU",
        "outputId": "630864de-8dca-4562-d3fc-1bd91bad9eb8"
      },
      "id": "v29qy9PSxKOU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found Keras model: ai/models/mlp_16_status_model.h5\n",
            "Saved artifact at '/tmp/tmpmcrbrv1m'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 4), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 3), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  139582012058000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582012048400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582012052240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  139582012056656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Saved quantized TFLite model to ai/models/mlp_status_model_quant.tflite size: 2624\n",
            "Generated C files: ai/models/mlp_status_model_quant.h ai/models/mlp_status_model_quant.cc\n",
            "Quantization cell finished.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}